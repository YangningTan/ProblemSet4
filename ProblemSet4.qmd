---
title: "ProblemSet4"
author: "Yangning Tan"
format: html
editor: visual
---

## Problem 1 - Tidyverse

```{r}
# install package
library(nycflights13)
library(tidyverse)
```

a.  Generate a table (which can just be a nicely printed tibble) reporting the mean and median departure delay per airport. Generate a second table (which again can be a nicely printed tibble) reporting the mean and median arrival delay per airport. Exclude any destination with under 10 flights. Do this exclusion through code, not manually.

    Additionally,

    -   Order both tables in descending mean delay.

    -   Both tables should use the airport *names* not the airport *codes*.

    -   Both tables should print all rows.

    ```{r}
    # mean and median of departure delay
    tb_flights <- nycflights13::flights

    tb_flights %>% 
      left_join(nycflights13::airports, by = c("origin" = "faa")) %>% 
      select(name, dep_delay) %>% 
      group_by(name) %>% 
      summarise(dep_delay_mean = mean(dep_delay, na.rm = TRUE),
                dep_delay_median = median(dep_delay, na.rm = TRUE)) %>% 
      arrange(desc(dep_delay_mean))
    ```

    ```{r}
    # mean and median of arrival delay
    tb_flights %>%
      #left_join(nycflights13::airports, by = c("dest" = "faa")) %>%
      group_by(dest) %>%
      filter(n() >= 10) %>%
      ungroup() %>% 
      select(dest, arr_delay) %>%
      group_by(dest) %>%
      summarise(arr_delay_mean = mean(arr_delay, na.rm = TRUE),
                arr_delay_median = median(arr_delay, na.rm = TRUE)) %>% 
      left_join(nycflights13::airports, by = c("dest" = "faa")) %>%
      select(name, arr_delay_mean, arr_delay_median) %>% 
      arrange(desc(arr_delay_mean))
    ```

b.  How many flights did the aircraft model with the fastest average speed take? Produce a tibble with 1 row, and entires for the model, average speed (in MPH) and number of flights.

    We first create a tibble of the planes.

    ```{r}
    tb_planes <- nycflights13::planes
    ```

    We need to get the average speed of each aircraft. To do this, we join the tibble of flights and planes.

    ```{r}
    tb_flights %>% 
      left_join(tb_planes, by = c("tailnum" = "tailnum")) %>% 
      select(model, distance, air_time) %>% 
      group_by(model) %>% 
      summarise(total_distance = sum(distance, na.rm = TRUE),
                total_time = sum(air_time, na.rm = TRUE) / 60,
                average_speed = total_distance / total_time,
                number_of_flights = n()) %>% 
      ungroup() -> average_speed
    ```

    Then, we can find out the model of plane with the fastest average speed.

    ```{r}
    average_speed %>% 
      filter(average_speed == max(average_speed)) %>% 
      select(model, average_speed, number_of_flights) -> fastest_model
    fastest_model
    ```

## Problem 2

Load the Chicago NNMAPS data we used in the visualization lectures. Write a function `get_temp()` that allows a user to request the average temperature for a given month.

We first import the data.

```{r}
nnmaps <- read.csv("/Users/tyn/Documents/R/chicago-nmmaps.csv")
```

Then we write the function.

```{r}
get_temp <- function(month_input, year_input, data, celsius = FALSE, average_fn = mean){
  # check the validity of input year
  if (year_input < 1997 | year_input > 2000) {
    stop("Invalid input: Year should be between 1997 and 2000")
  }
  
  # convert all kinds of input of month into numeric form
  convert_month_to_numeric <- function(month_input) {
  month_mapping <- c("Jan" = 1, "Feb" = 2, "Mar" = 3, "Apr" = 4, "May" = 5, "Jun" = 6, "Jul" = 7, "Aug" = 8, "Sep" = 9, "Oct" = 10, "Nov" = 11, "Dec" = 12)
  
  if (is.numeric(month_input)) {
    # Check if the input is a numeric value between 1 and 12
    if (month_input >= 1 && month_input <= 12) {
      return(month_input)
    } else {
      stop("Invalid input: Numeric month should be between 1 and 12.")
    }
  } else if (is.character(month_input)) {
    # Check if the input is a valid month name or abbreviation
    formatted_input <- substr(month_input, 1, 3)
    if (formatted_input %in% names(month_mapping)) {
      return(month_mapping[formatted_input])
    } else {
      stop("Invalid input: Not a recognized month name or abbreviation.")
    }
  } else {
    stop("Invalid input: Input should be a numeric value, a valid month name, or a valid month abbreviation.")
    }
  }
  month_input <- convert_month_to_numeric(month_input)
  
  # filter the data
  filtered_data <- data %>%
    select(temp, year, month_numeric) %>% 
    group_by(year, month_numeric) %>% 
    summarize(mean_temp = average_fn(temp)) %>% 
    ungroup() %>% 
    filter(year == year_input, month_numeric == month_input)
  
  average_temp <- filtered_data$mean_temp
  
  # transfer into celsius if necessary
  if (celsius) {
    average_temp <- (average_temp - 32) * 5/9
  }
    
  return(average_temp)
}
```

Finally, we check whether the code works.

```{r}
# valid input
get_temp("Apr", 1999, data = nnmaps)
get_temp("Apr", 1999, data = nnmaps, celsius = TRUE)
get_temp(10, 1998, data = nnmaps, average_fn = median)
get_temp("November", 1999, data =nnmaps, celsius = TRUE,
         average_fn = function(x) {
           x %>% sort -> x
           x[2:(length(x) - 1)] %>% mean %>% return
         })
```

If the input is valid, we can get a result. When the input is invalid, it can produce a reasonable error message.

## Problem 4

a.  Take a look at the Codebook. For very minor extra credit, how was the Codebook generated?

    It indicates the origin of the data set. In fact, some of the data is not included in this public version. Also, it lists all the variables. For each variable, it further provides a summary.

b.  Import the data into SAS and use `proc sql` to select only the variables you'll need for your analysis, as well as subsetting the data if needed.

    ```         
    data fin;
     set in_lib.public2022;
    run;

    proc sql;
      create table fin_filtered as
      select CaseID, B3, ND2, B7_a, GH1, ppeducat, race_5cat ,weight_pop
      from fin;
    quit;
    ```

c.  Get the data out of SAS and into Stata. 

    We export a csv file from SAS first.

    ```         
    proc export data=fin_filtered
        outfile = "&out_path./fin.csv"
        dbms=csv;
    run;
    ```

d.  Demonstrate that you've successfully extracted the appropriate data by showing the number of observations and variables.

    ```         

    Contains data
     Observations:        11,667                  
        Variables:             8                  
    -----------------------------------------------------------------------------------------
    Variable      Storage   Display    Value
        name         type    format    label      Variable label
    -----------------------------------------------------------------------------------------
    caseid          int     %8.0g                 CaseID
    b3              byte    %8.0g                 B3
    nd2             byte    %8.0g                 ND2
    b7_a            byte    %8.0g                 B7_a
    gh1             byte    %8.0g                 GH1
    ppeducat        byte    %8.0g                 
    race_5cat       byte    %8.0g                 
    weight_pop      float   %9.0g                 
    -----------------------------------------------------------------------------------------
    ```

e.  The response variable is a Likert scale; convert it to a binary of worse off versus same/better.

    ```         
    .gen fin_sit = .
    .replace fin_sit = 0 if b3 <= 2
    .replace fin_sit = 1 if b3 >= 3
    ```

f.  Carry out a logisitic regression model accounting for the complex survey design. Be sure to treat variables you think should be categorical appropriately. From these results, provide an answer to the researchers question of interest.

    ```         
    .svyset caseid [pw=weight_pop]
    .svy: logit fin_sit nd2 i.b7_a i.gh1 i.ppeducat i.ppethm

    Survey: Logistic regression

    Number of strata =      1                        Number of obs   =      11,667
    Number of PSUs   = 11,667                        Population size = 255,114,223
                                                     Design df       =      11,666
                                                     F(14, 11653)    =       66.18
                                                     Prob > F        =      0.0000

    ------------------------------------------------------------------------------
                 |             Linearized
         fin_sit | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
    -------------+----------------------------------------------------------------
             nd2 |   .0129984   .0301666     0.43   0.667    -.0461333      .07213
                 |
            b7_a |
              2  |   .8073133   .0599228    13.47   0.000     .6898546    .9247721
              3  |   1.762449   .0678032    25.99   0.000     1.629544    1.895355
              4  |   2.610153    .198261    13.17   0.000     2.221528    2.998778
                 |
             gh1 |
              2  |  -.0312602   .0563695    -0.55   0.579    -.1417537    .0792334
              3  |   .1215956   .0588709     2.07   0.039     .0061987    .2369924
              4  |   .3738337   .0977268     3.83   0.000     .1822728    .5653945
                 |
        ppeducat |
              2  |  -.0201906   .1020569    -0.20   0.843    -.2202393    .1798581
              3  |   .0137566   .0989573     0.14   0.889    -.1802162    .2077295
              4  |   .0792432    .098587     0.80   0.422    -.1140038    .2724902
                 |
       race_5cat |
              2  |   .8657323   .0806826    10.73   0.000     .7075809    1.023884
              3  |   .2735008   .0706689     3.87   0.000     .1349779    .4120236
              4  |   .5574518   .1242417     4.49   0.000     .3139174    .8009862
              5  |   .0153919   .1672565     0.09   0.927    -.3124588    .3432426
                 |
           _cons |  -.6296823    .135684    -4.64   0.000    -.8956456    -.363719
    ------------------------------------------------------------------------------

    . 
    ```

    We can see from the result of the logistic regression that when other variables are controlled, the p-value of variable "nd2" is greater than 0.05. Therefore, we get the conclusion that the coefficient is positive. This implies that **the respondent's family is better off, the same, or worse off finanicially compared to 12 month's ago** CAN be predicted by **thinking that the chance of experiencing a natural disaster or severe weather event will be higher, lower or about the same in 5 years**.

g.  Get the data out of Stata and into R.

    ```         
    .export delimited using "fin_2.csv", replace
    ```

h.  Obtain the pseudo-$R^2$ value for the logistic model fit above and report it.

    We first import the data.

    ```{r}
    dat <- read.csv("/Users/tyn/Documents/R/fin_2.csv")
    ```

    Now, we obtain the pseudo-$R^2$.

    ```{r}
    library(survey)
    # set up the complex survey design
    svy_design <- svydesign(id = ~ caseid, weight = ~ weight_pop, data = dat)
    # fit the logistic regression model
    survey_logit_model <- svyglm(fin_sit ~ nd2 + as.factor(b7_a) + as.factor(gh1) + as.factor(ppeducat) + as.factor(race_5cat), design = svy_design, family = quasibinomial)
    # compute the pseudo R squared
    pseudo_r2 <- 1 - survey_logit_model$deviance / survey_logit_model$null.deviance
    pseudo_r2
    ```
